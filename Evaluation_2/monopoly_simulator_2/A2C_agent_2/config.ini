[hyper]  # hyper-parameter of vanilla A2C => '~/monopoly_simulator/vanilla_A2C_main_v4.py'
print_interval = 150
;learning_rate = 0.0005
;gamma = 0.98
;n_train_processes = 5
;update_interval = 5
max_train_steps = 500000
;hidden_state = 256
;action_space = 2
;state_num = 90
;actor_loss_coefficient = 1
;save_path = '/weights'
num_test = 200  #number of test games in the test process
learning_rate = 0.001
gamma = 0.99
n_train_processes = 1
update_interval = 5
hidden_state = 256
action_space = 2  # 2
state_num = 92  # 92
actor_loss_coefficient = 1
save_path = '/media/becky/GNOME-p3/Evaluation_2/monopoly_simulator_2/A2C_agent_2/weights'
input_vocab_size = 344
embedding_size = 10
gat_emb_size = 10
dropout_ratio = 0.2
entity_id_file_path = '/media/becky/GNOME-p3/Evaluation_2/monopoly_simulator_2/A2C_agent_2/matrix/entity.json'
entity_id_file_path_state = '/media/becky/GNOME-p3/KG_rule/log_file'
adj_path = '/media/becky/GNOME-p3/KG_rule/matrix_rule/kg_matrix'
gat_output_size = 20  # graph -> nn -> output size
state_output_size = 50  # state -> nn -> output size
hidden_dim_gcn = 16


[env]  # hyper-parameter of environment => '~/env/monopoly_world.py'
num_active_players = 4
log_path = '/KG_rule/game_log.txt'  # File Path put the game simulation logging info
kg_save_interval = 10  # step of saving rule learning knowledge graph, not updating!!!!
initial_cash = 500  # Initial cash of this game
novelty_inject_num = 10  # The game rounds to inject novelty
rule_change_path = '/KG_rule/Rule_change.txt'  # A file to record rule change, just for visualization and debugging
kg_rel_path = '/KG_rule/json_kg.json'  # json file storing rule learning knowledge graph (type: dict())

[kg]  # hyper-parameter of knowledge graph => '~/KG_rule/openie_triple.py'
jsonfile = '/KG_rule/json_kg.json'  # json file storing rule learning knowledge graph (type: dict())
update_interval = 1  # step of updating rule learning knowledge graph
detection_num = 1500  # Novelty detection begins here for history recording
history_update_interval = 300  # Novelty detection interval for history recording

[matrix] # hyper-parameter of knowledge graph transition into matrix => '~/KG_rule/openie_triple.py'
entity_num = 40  # num of property
action_num = 40  # num of relations
matrix_folder= '/Evaluation_2/monopoly_simulator_2/A2C_agent_2/logs'  # folder storing matrix
vector_file = '/KG_rule/vector.npy'  # numpy file of vector generated from rule learning

[novelty]
percentage_var = 0.05  # the confidence interval of ks test for history recording

[server]
rule_change_name = '/Rule_change.txt'
log_file_name = '/game_log.txt'